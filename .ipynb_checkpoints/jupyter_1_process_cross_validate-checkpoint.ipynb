{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9b06b4-c08d-4502-a92c-b71aa2b4e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "format_log = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(filename='process_cross_validated.log', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef09b206-930a-41e8-b710-71093091e823",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Process Dialogflow K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0a59b-eff2-49f7-886a-125c92c30ddb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Overview\n",
    "This is a Jupyter notebook to complete a stratified K-fold cross validation on Dialogflow training examples. Cross validation on the training data tests the models ability to generalize on a random sample a data and partitions out a portion of the training data to be tested on. Testing the model on data it has never seen before helps validate what the model has learned. If you didn't test on data the model has not seen before, it would be looking at a tests answers before taking the test. Not a great evaluation of what you learned.  \n",
    "\n",
    "To learn more about K-fold view the links below:\n",
    "+ [YouTube: Machine Learning Video on Cross Validation](https://www.youtube.com/watch?v=fSytzGwwBVw)\n",
    "+ [Medium: 5 Reasons why you should use Cross-Validation in your Data Science Projects](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79)\n",
    "\n",
    "### Notebook Steps\n",
    "The high level steps followed in the notebook are listed below:\n",
    "1. Intialize all the parameters you need to run the notebook\n",
    "2. Load the functions\n",
    "3. Get intents, entities, training phrases and knowledge bases from Main Dialogflow agent\n",
    "4. Create k-folds and Loop through each k-fold partition:\n",
    "    + Build a dictionary to flatten the intents with phrases\n",
    "    + Creates a new agent\n",
    "    + Uploads intents knowledge base and training phrases to new agent\n",
    "    + Trains the new agent\n",
    "    + Makes intent predictions with the test data held out for validation\n",
    "    + Puts the test phrase, actual intent, dialogflow predicted intent, dialogflow predicted confidence score into a Pandas Table\n",
    "    + Appends the panda table to list to keep all the cross-validation results from all the loops.\n",
    "5. Save the cross validation results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac101d4-4974-4714-abc6-604bddeaaf6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Intialize all the parameters you need to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc1d564-804c-4061-8a6b-0781ee839ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "logging.info(\"Processing the k-fold cross-validation started\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from random import seed\n",
    "from random import randint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#from google.cloud import dialogflow\n",
    "from google.cloud import dialogflow_v2beta1 as dialogflow\n",
    "\n",
    "logging.info(\"Python libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccedb503-7859-47c6-be0b-b9bc20c009d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud JSON credentials\n",
    "google_cloud_json_credentials_file_name = 'google_cloud_credentials.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_cloud_json_credentials_file_name\n",
    "\n",
    "logging.info(\"Google Cloud Credentials Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd87bdaf-a2dc-4f5f-a189-8e2e570415be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main agents project id\n",
    "main_project_id = 'burgerbot-bskc'\n",
    "\n",
    "# test agent project id\n",
    "test_project_id = 'burgerbot-bskc-test-agent'\n",
    "\n",
    "# the name for test agent in Dialogfow\n",
    "test_agent_display_name = 'nlp_testing_agent'\n",
    "\n",
    "#file path to filter intents that are trainable\n",
    "trainable_file_path = 'data/input/trainable_intents/'\n",
    "#file name to filter intents that are trainable\n",
    "trainable_file_name = 'DoloresTraining_Current_4.xlsx'\n",
    "#sheet name to filter intents that are trainable\n",
    "trainable_sheet_name = 'EN locale - Training Queries'\n",
    "#column that contain information to filter intents\n",
    "trainable_use_cols = 'A,C,I,L'\n",
    "\n",
    "# the default language for the test agent\n",
    "default_language_code=\"en\"\n",
    "\n",
    "# the time zone for the test agent\n",
    "use_time_zone=\"America/Los_Angeles\"\n",
    "\n",
    "# api version of agent\n",
    "api_version = 'API_VERSION_V2_BETA_1'\n",
    "\n",
    "# pricing tier to use testing dialogflow agent\n",
    "use_tier=\"TIER_STANDARD\"\n",
    "#use_tier=\"TIER_ENTERPRISE\"\n",
    "\n",
    "# number of k-folds to complete\n",
    "number_of_k_splits = 5\n",
    "\n",
    "# the delay time between api requests and general pauses to prevent the API quota issues (recommend 60 sec)\n",
    "api_sleep_time = 60\n",
    "\n",
    "# the number of number of requests to complete before backing up to prevent API quota issues (recommend 50-55)\n",
    "api_interval_limit = 50\n",
    "\n",
    "logging.info(\"Parameters initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc7bf03-0a1c-4218-bd5c-77148f9266d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file name to save the results to\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "save_file_name = \"{}_cross_valid_results_.pickle\".format(dt_string)\n",
    "save_file_path = \"data/processed/\"\n",
    "\n",
    "# createing paths in main agent and test agents that will used for API calls\n",
    "main_project_path = 'projects/{}'.format(main_project_id)\n",
    "main_agent_path = 'projects/{}/agent'.format(main_project_id)\n",
    "\n",
    "test_project_path = 'projects/{}'.format(test_project_id)\n",
    "test_agent_path = 'projects/{}/agent'.format(test_project_id)\n",
    "\n",
    "# creating all the clients needed to complete the job\n",
    "agent_client = dialogflow.AgentsClient()\n",
    "intent_client = dialogflow.IntentsClient()\n",
    "entity_type_client = dialogflow.EntityTypesClient()\n",
    "session_client = dialogflow.SessionsClient()\n",
    "kb_client = dialogflow.KnowledgeBasesClient()\n",
    "doc_client = dialogflow.DocumentsClient()\n",
    "\n",
    "# intializating the the intent view for the function get_training_phrases\n",
    "intent_view = dialogflow.IntentView.INTENT_VIEW_FULL\n",
    "\n",
    "\n",
    "logging.info(\"Initial variables created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0c9cd-6f57-45c8-9948-4ff2a84d688d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558cd514-f004-489c-bc62-9a3d2f132cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_phrases(dict_key, intent_client):\n",
    "    '''\n",
    "    Overview: A function to get training phrases associated with a Dialogflow intent\n",
    "    Depends On Function: None\n",
    "    Constraints: You have a list intents in a dictionary from Dialogfow in the following format:\n",
    "    \n",
    "    'projects/burgerbot-bskc/agent/intents/0026647a-e6a1-46bb-9835-bc7e4962efe5': ('faq1.00-warranty.square.trade','0026647a-e6a1-46bb-9835-bc7e4962efe5'),\n",
    "    \n",
    "    Input:\n",
    "        1. dict_key (str): The key value associated with the intent dictionary created\n",
    "        2. intent_client (Dialogflow intent client session): Ex: intent_client = dialogflow.IntentsClient()\n",
    "        \n",
    "    Output:\n",
    "        1. intent_name (str): The name of intent in string format\n",
    "        2. phrases (list): All the phrases associated with the intent in list format\n",
    "    \n",
    "    '''\n",
    "    intent_path = dict_key\n",
    "    intent_name = intent_dict[key]['intent_name']\n",
    "    get_intent_request = dialogflow.GetIntentRequest(name=intent_path, intent_view=intent_view)\n",
    "    intent_returned = intent_client.get_intent(get_intent_request)\n",
    "    phrases = list(intent_returned.training_phrases)\n",
    "    #entities = \n",
    "    return intent_name, phrases\n",
    "\n",
    "\n",
    "\n",
    "def upload_training_phrases(dict_key, intent_client):\n",
    "    '''\n",
    "    Overview: A function to upload intents and training phrases to Dialogflow\n",
    "    Depends On Function: None\n",
    "    Constraints: \n",
    "        1. A properly formated dictionary object: {intent name : [phrase 1, phrase 2, phrase 3...phrase x]}\n",
    "    Input: \n",
    "        1. dict_key (dictionary):\n",
    "        2. intent_client (Dialogflow intent client session): Ex: intent_client = dialogflow.IntentsClient()\n",
    "    Output: \n",
    "        1. Intent created in Dialogflow with associated training phrases\n",
    "    '''\n",
    "    intent_name = dict_key #save intent name\n",
    "    # loop through dictionary\n",
    "    training_phrases = []\n",
    "    training_phrases_parts = phrase_dict[key]\n",
    "    for training_phrases_part in training_phrases_parts:\n",
    "        part = dialogflow.Intent.TrainingPhrase.Part(\n",
    "            text=training_phrases_part)\n",
    "        # Here we create a new training phrase for each provided part.\n",
    "        training_phrase = dialogflow.Intent.TrainingPhrase(parts=[part])\n",
    "        training_phrases.append(training_phrase)\n",
    "\n",
    "    intent = dialogflow.Intent(display_name = intent_name, training_phrases = training_phrases)\n",
    "    create_intent_request = dialogflow.CreateIntentRequest(parent=test_agent_path, intent=intent)\n",
    "    try:\n",
    "        response = intent_client.create_intent(create_intent_request)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "def batch_upload_training_phrases(dict_key, intent_client):\n",
    "    intent_name = dict_key #save intent name\n",
    "    \n",
    "\n",
    "def random_with_N_digits(n):\n",
    "    '''\n",
    "    Overview: A function to create 9 random digits for a Dialogflow session\n",
    "    Depends On Function: None\n",
    "    Constraints: Input must be an integer\n",
    "    Input: \n",
    "        1. n (int): Ex: 9\n",
    "    Output: \n",
    "        1. Nine random digits (int). Ex: 227454785\n",
    "    '''\n",
    "    range_start = 10**(n-1)\n",
    "    range_end = (10**n)-1\n",
    "    return randint(range_start, range_end)\n",
    "\n",
    "\n",
    "def dialogflow_prediction(input_text, language_code, session, query_params):\n",
    "    '''\n",
    "    Overview: A function to predict the intent name and confidence score from Dialogflow\n",
    "    Depends On Function: None\n",
    "    Constraints: A Dialogflow session created and string of text less than 768 characters (10/1/21). \n",
    "    Input: \n",
    "        1. input_text (str): The phrase you want to predict. \n",
    "        2. language_code (str): The language you are predicting\n",
    "        3. session (dialogflow session): A diaogflow session to have the correct permissions.\n",
    "        4. query_params (dialogflow knowledge base): A path to a dialogflow knowledge base to make predictions\n",
    "    Output:\n",
    "        1. predicted intent name (str), confidence score of prediction (float)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    text_input = dialogflow.TextInput(text=input_text, language_code=language_code)\n",
    "    query_input = dialogflow.QueryInput(text=text_input)\n",
    "    request = dialogflow.DetectIntentRequest(session=session, query_input=query_input, query_params=query_params)\n",
    "    response = session_client.detect_intent(request=request)   \n",
    "    #response = session_client.detect_intent(request={\"session\": session, \"query_input\": query_input})\n",
    "    predicted_intent_name = response.query_result.intent.display_name\n",
    "    predicted_confid_score = response.query_result.intent_detection_confidence\n",
    "    return predicted_intent_name, predicted_confid_score\n",
    "\n",
    "def create_entity_type_list_from_DF_list(dialogflow_entity_list):\n",
    "    '''\n",
    "    Overview: A function to create entities in a new Dialogflow agent \n",
    "    Depends On Function: None\n",
    "    Constraints: Entity list must be in the format of entity_types.pagers.ListEntityTypesPager. \n",
    "                 Ex: entity_types_list = entity_type_client.list_entity_types(parent=agent_path)\n",
    "    Input:\n",
    "        1. dialogflow_entity_list (list): A Dialogflow list of entity of types\n",
    "        2. test_project_id (str): The test project name to upload the entities to\n",
    "    Output:\n",
    "        2. entity_upload_list (list): A list entities that can input into a Dialogflow to create batches entities of once in Dialogflow \n",
    "    '''\n",
    "    entity_upload_list = []\n",
    "    entity_list = list(dialogflow_entity_list)\n",
    "\n",
    "    for i in range(len(entity_list)):\n",
    "        entity_type_display_name = entity_list[i].display_name\n",
    "        entity_type_kind = entity_list[i].kind\n",
    "        entity_type_entities = entity_list[i].entities\n",
    "        entity = dialogflow.EntityType(display_name=entity_type_display_name, kind=entity_type_kind, entities=entity_type_entities)\n",
    "        entity_upload_list.append(entity)\n",
    "\n",
    "    return entity_upload_list\n",
    "\n",
    "\n",
    "def batch_create_entity_types(entity_list, entity_client, agent_path):\n",
    "    '''\n",
    "    Overview: A function to upload a batch of entity types to Dialogflow\n",
    "    Depends On Function: None\n",
    "    Constraints:\n",
    "        1. The entity_list must be in the format like the function create_entity_type_list_from_DF_list outputs. \n",
    "        2. The entity types must NOT already exist in the agent they are being added to. \n",
    "    Input:\n",
    "        1. entity_list (list):  A list entities that can input into a Dialogflow to create batches entities of once in Dialogflow \n",
    "        2. entity_client (Dialogflow EntityTypesClient): The Dialogflow entity client used to make API calls to entity types\n",
    "        3. agent_path (str): The path to agent you wish to upload the entity types to: Ex: projects/burgerbot-bskc-test-agent/agent\n",
    "        \n",
    "    Outputs:\n",
    "        1. response: The response from Dialogflow\n",
    "    '''\n",
    "    entity_types: List[dialogflow.EntityType] = entity_list\n",
    "    entity_types_batch = dialogflow.EntityTypeBatch(entity_types=entity_types)\n",
    "    batch_update_entity_type_request = dialogflow.BatchUpdateEntityTypesRequest(parent=agent_path, entity_type_batch_inline=entity_types_batch)\n",
    "    response = entity_client.batch_update_entity_types(batch_update_entity_type_request, timeout=120)\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_intent_list(intents, ignore_ml_disabled=True):\n",
    "    '''\n",
    "    Oveview: A function to create a dictionary of intents to create in test agent\n",
    "    Depends On: None\n",
    "    Constraints: Function has been tested mostly igorning intents disabled for machine learning. \n",
    "    Input:\n",
    "        1. intents (ListIntentsPager): A list of intents from Dialogflow API\n",
    "    Outputs:\n",
    "        1. intent_dict (dict): A dictionary containing intent path as the key and the intent display name and intent id as values\n",
    "        Ex: projects/burgerbot-bskc/agent/intents/01a0d3bf-582a-4f4a-81b2-67763d65f6b4': ('ask_transfer_charge', '01a0d3bf-582a-4f4a-81b2-67763d65f6b4')\n",
    "    \n",
    "    '''\n",
    "    intent_dict = {}\n",
    "    if  ignore_ml_disabled==True:\n",
    "        # save intent ids to list\n",
    "        for intent in intents:\n",
    "            intent_path = intent.name\n",
    "            ml_disabled = intent.ml_disabled\n",
    "            if ml_disabled == False:\n",
    "                intent_display_name = intent.display_name\n",
    "                splitted = str(intent_path).split(\"/\")\n",
    "                intent_id = splitted[-1]\n",
    "                intent_dict[intent_path] = (intent_display_name, intent_id)\n",
    "            else:\n",
    "                pass\n",
    "        return intent_dict\n",
    "    \n",
    "    if ignore_ml_disabled==False:\n",
    "        # save intent ids to list\n",
    "        for intent in intents:\n",
    "            intent_path = intent.name\n",
    "            ml_disabled = intent.ml_disabled\n",
    "            if ml_disabled == False:\n",
    "                intent_display_name = intent.display_name\n",
    "                splitted = str(intent_path).split(\"/\")\n",
    "                intent_id = splitted[-1]\n",
    "                intent_dict[intent_path] = (intent_display_name, intent_id)\n",
    "            else:\n",
    "                pass\n",
    "        return intent_dict   \n",
    "            \n",
    "\n",
    "def load_trainable_intents(trainable_file_path, trainable_file_name, trainable_sheet_name, trainable_use_cols, google_sheet=False):\n",
    "    '''\n",
    "    Overview: A function to load an Excel file of intents to train and not train in Dialogflow\n",
    "    Depends On: Having an excel sheet in a certain format of intents to train\n",
    "    Constraints: The format of the Excel spreadsheet should not change\n",
    "    Input:\n",
    "        1. trainable_file_path (str): The path on local computer the excel spreadsheet of trainable intents exists\n",
    "        2. trainable_file_name (str): The file name of the excel spreadsheet of trainable intents\n",
    "        3. trainable_sheet_name (str): The Excel sheet name to load of the Excel spreadsheet of trainable intents\n",
    "        4. trainable_use_cols (str): A list of columns to load from the Excel spreadhsheet. Ex: A,B,G\n",
    "    Output:\n",
    "        1. train_intent_df (pandas dataframe): A dataframe of intent_name, with a value of 1 or 0 if the intent should be trained\n",
    "    '''\n",
    "    \n",
    "    if google_sheet==False:\n",
    "        train_intent_df = pd.read_excel(trainable_file_path+trainable_file_name, sheet_name=trainable_sheet_name, usecols=trainable_use_cols)\n",
    "        train_intent_df = train_intent_df[train_intent_df['trainable?'] == 'Yes']\n",
    "        train_intent_df['utterance_change'] = train_intent_df['utterance_change'].fillna('')\n",
    "        train_intent_df['utterance_change'] = [x.strip() for x in train_intent_df['utterance_change']]\n",
    "        train_intent_df['utterance_change'] = [x.lower() for x in train_intent_df['utterance_change']]\n",
    "\n",
    "        train_intent_df = train_intent_df[train_intent_df['utterance_change'] != 'remove']\n",
    "        train_intent_df = train_intent_df.rename(columns={'intentName': 'intent name', 'text':'train'}) \n",
    "\n",
    "        intent_count = train_intent_df.groupby('intent name')['train'].count().reset_index()\n",
    "        intent_count['train'] = 1\n",
    "        train_intent_df = intent_count.set_index('intent name')\n",
    "        return train_intent_df\n",
    "        \n",
    "    else:\n",
    "        train_intent_df = pd.read_excel(trainable_file_path+trainable_file_name, sheet_name=trainable_sheet_name, usecols=trainable_use_cols)\n",
    "        train_intent_df = train_intent_df.reset_index(drop=True)\n",
    "        train_intent_df = train_intent_df.rename(columns={'Training?':'train'})\n",
    "        train_intent_df['train'] = np.where(train_intent_df['train']=='Yes',1,0)\n",
    "        train_intent_df = train_intent_df.set_index('intent name')\n",
    "        return train_intent_df\n",
    "\n",
    "\n",
    "def filter_trainable_intents(dialogflow_intent_dict, trainable_file_path, trainable_file_name, trainable_sheet_name, trainable_use_cols): \n",
    "    '''\n",
    "    Overview: A function to filter intents that are not supposed to be trained on\n",
    "    Depends On: \n",
    "        1. Having an excel sheet in a certain format of intents to train\n",
    "        2. The function load_trainable_intents\n",
    "    Contraints: None\n",
    "    Input:\n",
    "        1. dialogflow_intent_dict (dict): A dictionary of dialogflow intents\n",
    "        2. trainable_file_path (str): The path on local computer the excel spreadsheet of trainable intents exists\n",
    "        3. trainable_file_name (str): The file name of the excel spreadsheet of trainable intents\n",
    "        4. trainable_sheet_name (str): The Excel sheet name to load of the Excel spreadsheet of trainable intents\n",
    "        5. trainable_use_cols (str): A list of columns to load from the Excel spreadhsheet. Ex: A,B,G\n",
    "    Output:\n",
    "        1. intect_dict (dict): A filtered dictionary of dialogflow intents\n",
    "    '''\n",
    "    df_train = load_trainable_intents(trainable_file_path, trainable_file_name, trainable_sheet_name, trainable_use_cols)\n",
    "    \n",
    "    intent_df = pd.DataFrame.from_dict(dialogflow_intent_dict).transpose().reset_index()\n",
    "    intent_df = intent_df.rename(columns={'index':'intent_path',0:'intent_name',1:'intent_id'})\n",
    "    intent_df = intent_df.set_index('intent_name')\n",
    "    intent_df = intent_df.merge(df_train, how='left', left_index=True, right_index=True)\n",
    "    intent_df['train'] = intent_df['train'].fillna(0).astype(int)\n",
    "    intent_df = intent_df[intent_df['train']==1]\n",
    "    \n",
    "    intent_df = intent_df.reset_index()\n",
    "    intent_df = intent_df.rename(columns={'index':'intent_name'})\n",
    "    intent_df = intent_df.drop_duplicates(subset=['intent_path'], keep='last')\n",
    "    intent_df = intent_df.set_index('intent_path')\n",
    "    intect_dict = intent_df.to_dict(orient='index')\n",
    "    return intect_dict\n",
    "\n",
    "def pepare_df_text_for_prediction(dialogflow_phrases):\n",
    "    '''\n",
    "    Overview: A function to transform the training data which is in Dialogflow parts to raw text to make predictions.\n",
    "    Depends On Function: None\n",
    "    Constraints: The data input must must be array and Dialogflow parts of training phrases\n",
    "    Input:\n",
    "        1. dialogflow_phrases (array): An array of Dialogflow parts of training phrases\n",
    "    Output:\n",
    "        1. prediction_list (list): A list of training phrases converted from Dialogflow parts to raw text. \n",
    "    '''\n",
    "    \n",
    "    prediction_list = []\n",
    "    for text in dialogflow_phrases:\n",
    "        if len(text) >= 2:\n",
    "            new_list = []\n",
    "            for words in text:\n",
    "                new_list.append(words.text)\n",
    "\n",
    "            new_list = \"\".join(new_list)\n",
    "            prediction_list.append(new_list)\n",
    "        else:\n",
    "            prediction_list.append(text[0].text)\n",
    "            \n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "# get existing knowledge ids\n",
    "def get_existing_knowledge_graph_id(project_id, client, keep_list):\n",
    "    '''\n",
    "    Overview: A function to get a list of knowledge bases in Dialgflow and filter out ones to keep\n",
    "    Depends On Function: None\n",
    "    Constraints:\n",
    "    Input:\n",
    "        1. project_id (str): The main agents project\n",
    "        2. client (Dialogflow KnowledgeBasesClient): The intialized Dialogflow client to work with Knowledge Base)\n",
    "        3. keep_list (list): A list containing the string of Knowledge Bases names from the Main Agent you want to copy to the test agent.\n",
    "    Output:\n",
    "        1. A list of knowledge bases to to use for cross validation in the Test Agent.\n",
    "    '''\n",
    "    parent_path = 'projects/{}'.format(project_id)\n",
    "    kb_list = client.list_knowledge_bases(parent=parent_path)\n",
    "    \n",
    "    #filter any KB's you want to keep or not keep\n",
    "    kb_list_keep = []\n",
    "    for kb in kb_list:\n",
    "        if kb.display_name in keep_list:\n",
    "            kb_list_keep.append(kb)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return kb_list_keep\n",
    "\n",
    "\n",
    "def get_knowledge_base(project_id, kb_client, knowledge_base_id):\n",
    "    '''\n",
    "    Overview: A function to retrive a certain knowledge base from Dialogflow\n",
    "    Depends On Function: None\n",
    "    Constraints: \n",
    "    Input:\n",
    "        1. project_id (str): The Google Cloud project the Dialogflow bot is in\n",
    "        2. kb_client (Dialogflow Knowledge Graph Client): The Dialogflow knowlege base client\n",
    "        3. knowledge_base_id (str): The Dialogflow knowledge base id of the knowledge base you want to retrieve. \n",
    "    Output:\n",
    "        1. The dialogflow flow knowledge base \n",
    "    '''\n",
    "    knowledge_base_path = kb_client.knowledge_base_path(project_id, knowledge_base_id)\n",
    "    response = kb_client.get_knowledge_base(name=knowledge_base_path, timeout=240)\n",
    "    return response\n",
    "\n",
    "def get_knowledge_base_docs(project_id, kb_client, doc_client, knowledge_base_id):\n",
    "    '''\n",
    "    Overview: A function to get list of documents stored in a Dialogflow knowledge base\n",
    "    Depends On Function: \n",
    "    Constraints: \n",
    "    Input:\n",
    "        1. project_id (str): The Google Cloud project the Dialogflow bot is in\n",
    "        2. kb_client (Dialogflow Knowledge Graph Client): The Dialogflow knowlege base client\n",
    "        3. doc_client (Dialoflow Document Client): The Dialogflow document client\n",
    "        4. knowledge_base_id (str): The Dialogflow knowledge base id of the knowledge base you want to retrieve documents from. \n",
    "    Output:\n",
    "        1. A list of documents that are stored in a Dialogflow knowledge base\n",
    "    '''\n",
    "    knowledge_base_path = kb_client.knowledge_base_path(project_id, knowledge_base_id)\n",
    "    response = doc_client.list_documents(parent=knowledge_base_path, timeout=240)\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_empty_knowledge_base(project_id, kb_client, display_name):\n",
    "    '''\n",
    "    Overview: A function to create an empty knowledge base in Dialogflow\n",
    "    Depends on Function:\n",
    "    Constraints:\n",
    "    Input:\n",
    "        1. project_id (str): The Google Cloud project the Dialogflow bot is in\n",
    "        2. kb_client (Dialogflow Knowledge Graph Client): The Dialogflow knowlege base client\n",
    "        3. display_name (str): The name you want the new knowledge base to have\n",
    "    Output:\n",
    "        1. A new knowledge base created in Dialogflow\n",
    "        \n",
    "    '''\n",
    "    parent_path = 'projects/{}'.format(project_id)\n",
    "    knowledge_base = dialogflow.KnowledgeBase(display_name=display_name)\n",
    "    response = kb_client.create_knowledge_base(parent=parent_path, knowledge_base=knowledge_base, timeout=120)\n",
    "    return response\n",
    "\n",
    "def add_doc_to_knowledge_base(project_id, doc_client, knowledge_base_id, display_name, mime_type, raw_content, knowledge_type):\n",
    "    '''\n",
    "    Overview: A function to add Dialogflow document to a Dialogflow knowledge base\n",
    "    Depends On Function:\n",
    "    Constraints:\n",
    "    Input:\n",
    "        1. project_id (str): The Google Cloud project the Dialogflow bot is in\n",
    "        2. doc_client (Dialoflow Document Client): The Dialogflow document client\n",
    "        3. knowledge_base_id (str): The Dialogflow knowledge base id of the knowledge base you want to retrieve documents from\n",
    "        4. display_name (str): The name you want the new document to have\n",
    "        5. mime_type (str): The MIME type of the Dialogflow document.\n",
    "        6. raw_content (str): The raw content of the Dialogflow document. This field is only permitted for EXTRACTIVE_QA and FAQ knowledge types.\n",
    "        7. knowledge_type (list): The knowledge types of the document. Like FAQ, Extractive QA. \n",
    "    Output:\n",
    "        1. Document created in Dialogflow knowledge base\n",
    "    '''\n",
    "                              \n",
    "    knowledge_base_path = dialogflow.KnowledgeBasesClient.knowledge_base_path(project_id, knowledge_base_id)\n",
    "    document = dialogflow.Document(display_name=display_name, mime_type=mime_type, raw_content=raw_content)\n",
    "    document.knowledge_types.append(getattr(dialogflow.Document.KnowledgeType, knowledge_type))\n",
    "    response = doc_client.create_document(parent=knowledge_base_path, document=document)\n",
    "    document = response.result(timeout=240)\n",
    "    print(\"Created Document:\")\n",
    "    print(\" - Display Name: {}\".format(document.display_name))\n",
    "    print(\" - Knowledge ID: {}\".format(document.name))\n",
    "    \n",
    "    \n",
    "logging.info(\"Functions created\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312e5d0-3a0b-43ed-b503-38328f1bc6b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Get intents, entities, training phrases and knowledge bases from Main Dialogflow agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d2e799-0036-443d-87e6-38e0aa97a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of intents from main agent\n",
    "\n",
    "intent_list = intent_client.list_intents(parent=main_agent_path)\n",
    "intent_dict = create_intent_list(intent_list)\n",
    "\n",
    "logging.info(\"Received list of intents from main agent\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3160563b-1b5a-4888-9acd-f7afaa4bc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to filter from a file, you can use this function. If not, comment it out.\n",
    "\n",
    "intent_dict = filter_trainable_intents(intent_dict, trainable_file_path, trainable_file_name, trainable_sheet_name, trainable_use_cols) \n",
    "\n",
    "logging.info(\"Filtered intents based off Excel file\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6825b7-c8af-44de-96a1-c3cb55e471fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all entity types from main agent\n",
    "\n",
    "entity_types_list = entity_type_client.list_entity_types(parent=main_agent_path)\n",
    "entity_types_list = create_entity_type_list_from_DF_list(entity_types_list)\n",
    "\n",
    "logging.info(\"Received entities from main agent\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6f9c83-5753-4d49-b849-6b3e3b801146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244/244 [05:17<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# get intent training phrases\n",
    "\n",
    "train_intent = []\n",
    "intent_assoc_parts = []\n",
    "#time.sleep(api_sleep_time) # wait 60 seconds before starting to prevent API quota issues\n",
    "\n",
    "'''\n",
    "This loop gets the key and value from intect_dict.\n",
    "It keeps track of how many times the loop has happened to keep under the Dialogflow free-tier API limit. If you go over the count limit,\n",
    "which is set in a variable function in the intialize section, the loop pauses for a certain amount of time, then restarts again. \n",
    "It uses the function get_training_phrases to get an intent name and all its associated training phrases\n",
    "    Another loop gets and invividual phrase from the phrase list\n",
    "    Phrases from Dialogflow have parts, so within one phrase you could have 4 parts. Parts could be just text or entities. \n",
    "        A third loop loops through all the intent parts and saves them to list. So you have intent name and all its associated\n",
    "        parts one-to-one. Which is the main output from all these loops. \n",
    "\n",
    "At this time, if an intent does have more than two training phrases, you cannot do cross-validation on it. So if an intent does have \n",
    "more than two phrases, it is skipped. \n",
    "        \n",
    "'''\n",
    "count = 0\n",
    "for key, v in tqdm(intent_dict.items()):\n",
    "    if count < api_interval_limit:\n",
    "        intent_name, phrases = get_training_phrases(key, intent_client)\n",
    "        if len(phrases) >= 2:\n",
    "            for phrase in phrases:\n",
    "                intent_parts = []\n",
    "                for i in range(len(phrase.parts)):\n",
    "                    intent_parts.append(phrase.parts[i])\n",
    "                \n",
    "                train_intent.append(intent_name)\n",
    "                intent_assoc_parts.append(intent_parts)\n",
    "                    \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        count +=1 \n",
    "    \n",
    "    elif count >=api_interval_limit:\n",
    "        time.sleep(api_sleep_time)\n",
    "        intent_name, phrases = get_training_phrases(key, intent_client)\n",
    "        if len(phrases) >= 2:\n",
    "            for phrase in phrases:\n",
    "                intent_parts = []\n",
    "                for i in range(len(phrase.parts)):\n",
    "                    intent_parts.append(phrase.parts[i])\n",
    "                \n",
    "                train_intent.append(intent_name)\n",
    "                intent_assoc_parts.append(intent_parts)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        count = 0\n",
    "\n",
    "logging.info(\"Received all intent training phrases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b33f9cd-6c11-40aa-9800-babc4447e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get existing knowledge base ids from main agent\n",
    "existing_kbs = get_existing_knowledge_graph_id(main_project_id, kb_client, keep_list=['QA_Pairs_US'])\n",
    "knowledge_base = existing_kbs[0]\n",
    "knowledge_base_id = knowledge_base.name.split('/')[-1]\n",
    "\n",
    "logging.info(\"Received all knowledge base ids from main agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b62186-f923-435f-a25d-7b7b7c7ce536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get documents from existing knowledge base in main agent\n",
    "existing_docs = get_knowledge_base_docs(main_project_id, kb_client, doc_client, knowledge_base_id)\n",
    "us_doc = existing_docs.documents[1]\n",
    "uk_doc = existing_docs.documents[0]\n",
    "\n",
    "logging.info(\"Received all relevant documents from main agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193591e1-ab9b-4939-8b89-db8a71520b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares data from loop above to be put in Pandas dataframe\n",
    "input_data = list(zip(intent_assoc_parts, train_intent))\n",
    "data = pd.DataFrame(data=input_data, columns=['parts','intent'])\n",
    "\n",
    "# X training values. The values that will be used to train (training phrases)\n",
    "# y prediction values. That values that will be predicted (intent name)\n",
    "X = data['parts'].values\n",
    "y = data['intent'].values\n",
    "\n",
    "logging.info(\"Split data into train and test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4154be65-407a-46fb-a2eb-e3c53af6ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare Dialogflow parts for prediction by converting parts to text\n",
    "#prediction_list = pepare_df_text_for_prediction(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f0805-2a5e-4a47-9cf8-a4c9c1ac5f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Create k-folds and Loop through each k-fold partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac010ff4-4414-41ba-844b-90ffcdcca690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting old project if one exists\n",
      "'NoneType' object has no attribute 'Call'\n",
      "Sleeping for 60 seconds...\n",
      "Looping through the folded data\n",
      "Creating agent\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_US\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/NzI3MTA4MTM4OTU5ODk2NTc2/documents/MTczNDI4MTczNTY5OTIyMTcwODg\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_UK\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/NzI3MTA4MTM4OTU5ODk2NTc2/documents/OTg0ODgyNzU3NzA0NzcxMTc0NA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 1472.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Agent 1\n",
      "Training Agent 2\n",
      "Making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3997/3997 [1:38:10<00:00,  1.47s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Agent\n",
      "Creating agent\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_US\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/MTMxMDA3NDgxMTUxNjAzMzQzMzY/documents/MTQwNjg3MDA0Mjc4OTM4NjY0OTY\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_UK\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/MTMxMDA3NDgxMTUxNjAzMzQzMzY/documents/MTc3Mzg3MzQ0NTE3MjQxMjQxNg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 1413.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Agent 1\n",
      "Training Agent 2\n",
      "Making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3997/3997 [1:37:54<00:00,  1.47s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Agent\n",
      "Creating agent\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_US\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/MTI4Mzk1MzkzMzY3NzI4NDU1Njg/documents/MTU3OTgwODI2ODQ4MDQxMzY5NjA\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_UK\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/MTI4Mzk1MzkzMzY3NzI4NDU1Njg/documents/MTQ3NDQyNDAzNzE5OTk0NDA4OTY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 1555.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Agent 1\n",
      "Training Agent 2\n",
      "Making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3997/3997 [1:38:42<00:00,  1.48s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Agent\n",
      "Creating agent\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_US\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/MTgwOTk3NDM3MDE1NDE1ODQ4OTY/documents/MTU1MDk4NTIzMDg2NTI0MjUyMTY\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_UK\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/MTgwOTk3NDM3MDE1NDE1ODQ4OTY/documents/MTM0NTE3MDcyNzg5NDQxMDg1NDQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 1556.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Agent 1\n",
      "Training Agent 2\n",
      "Making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [1:38:00<00:00,  1.47s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Agent\n",
      "Creating agent\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_US\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/NDQ5NDM2OTIyNzI1NTMxNjQ4MA/documents/MTA1NzgwMTEwNDQyMDUwMzU1Mg\n",
      "Created Document:\n",
      " - Display Name: QA_Pairs_UK\n",
      " - Knowledge ID: projects/burgerbot-bskc-test-agent/knowledgeBases/NDQ5NDM2OTIyNzI1NTMxNjQ4MA/documents/MTgwNTg4ODk2OTc3NDQxMjU5NTI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 1413.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Agent 1\n",
      "Training Agent 2\n",
      "Making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3996/3996 [1:38:18<00:00,  1.48s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Agent\n"
     ]
    }
   ],
   "source": [
    "#fold the data\n",
    "skf  = StratifiedKFold(n_splits=number_of_k_splits, shuffle=True, random_state=100)\n",
    "skf.get_n_splits(X)\n",
    "\n",
    "#delete agent if one already exists\n",
    "print(\"Deleting old project if one exists\")\n",
    "try:\n",
    "    \n",
    "    response = agent_client.delete_agent(parent=test_project_path, timeout=120)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "logging.info(\"Deleted the old agent\")\n",
    "\n",
    "print(\"Sleeping for 60 seconds...\")\n",
    "time.sleep(api_sleep_time) # wait 60 seconds before starting to prevent API quota issues\n",
    "\n",
    "\n",
    "# loop through the folded data\n",
    "print(\"Looping through the folded data\")\n",
    "logging.info(\"Looping through the folded data\")\n",
    "\n",
    "test_num = 1\n",
    "results_df = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    logging.info(\"The {} k-fold loop started\".format(test_num))\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # build dictionary of intents with values as list of training phrases\n",
    "    key_set = list(set(y_train))\n",
    "    phrase_dict = {key.strip() : [] for key in key_set}\n",
    "        \n",
    "    for i in range(len(y_train)):\n",
    "        key = y_train[i].strip()\n",
    "        value = X_train[i]\n",
    "        phrase_dict[key].append(value)\n",
    "        \n",
    "    logging.info(\"Built dictionary of intents with training phrases\")\n",
    "        \n",
    "    #create agent\n",
    "    print(\"Creating agent\")\n",
    "    agent = dialogflow.Agent(parent=test_project_path, display_name=test_agent_display_name, default_language_code=default_language_code, time_zone=use_time_zone, tier=use_tier)\n",
    "    response = agent_client.set_agent(request={\"agent\": agent}, timeout=240)\n",
    "    time.sleep(60) #added in case it goes too fast\n",
    "    logging.info(\"Created the agent\")\n",
    "    \n",
    "    # create new empty knowledge base\n",
    "    new_kb = create_empty_knowledge_base(test_project_id, kb_client, knowledge_base.display_name)\n",
    "    new_kb_id = new_kb.name.split(\"/\")[-1]\n",
    "    new_kb_path = dialogflow.KnowledgeBasesClient.knowledge_base_path(test_project_id, new_kb_id)\n",
    "    time.sleep(10) #added in case it goes too fast\n",
    "    logging.info(\"Created a new empty knowledge base\")\n",
    "\n",
    "    # add us document to new knowledge base\n",
    "    display_name = us_doc.display_name\n",
    "    mime_type = us_doc.mime_type\n",
    "    raw_content = us_doc.raw_content\n",
    "    knowledge_type = 'FAQ'\n",
    "    add_doc_to_knowledge_base(test_project_id, doc_client, new_kb_id, display_name, mime_type, raw_content, knowledge_type)\n",
    "    time.sleep(10) #added in case it goes too fast\n",
    "    logging.info(\"Added US document to knowledge base\")\n",
    "    \n",
    "    # add uk document to new knowledge base\n",
    "    display_name = uk_doc.display_name\n",
    "    mime_type = uk_doc.mime_type\n",
    "    raw_content = uk_doc.raw_content\n",
    "    knowledge_type = 'FAQ'\n",
    "    add_doc_to_knowledge_base(test_project_id, doc_client, new_kb_id, display_name, mime_type, raw_content, knowledge_type)\n",
    "    time.sleep(10) #added in case it goes too fast\n",
    "    logging.info(\"Added UK document to knowledge base\")\n",
    "    \n",
    "    # batch upload entity types from main agent to test agent.\n",
    "    batch_create_entity_types(entity_types_list, entity_type_client, test_agent_path)\n",
    "    time.sleep(60) #added in case it goes too fast\n",
    "    logging.info(\"Uploaded entity types from main agent to test agent\")\n",
    "    \n",
    "    #batch upload intents and training phrases to new agent\n",
    "    intent_upload_list = []\n",
    "    for key,v in tqdm(phrase_dict.items()):\n",
    "        intent_name = key #save intent name\n",
    "        if intent_name != 'Default Welcome Intent':\n",
    "            training_phrases = []\n",
    "            training_phrases_parts = phrase_dict[key]\n",
    "            #print(training_phrases_parts)\n",
    "            for part in training_phrases_parts:\n",
    "                #print(part)\n",
    "                training_phrase = dialogflow.Intent.TrainingPhrase(parts=part)\n",
    "                training_phrases.append(training_phrase)\n",
    "            intent = dialogflow.Intent(display_name = intent_name, training_phrases = training_phrases)\n",
    "            intent_upload_list.append(intent)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    intents: List[dialogflow.Intent] = intent_upload_list\n",
    "    intent_batch = dialogflow.IntentBatch(intents=intents)\n",
    "    batch_update_intent_request = dialogflow.BatchUpdateIntentsRequest(parent=test_agent_path, intent_batch_inline=intent_batch)\n",
    "    response = intent_client.batch_update_intents(batch_update_intent_request, timeout=120)\n",
    "    logging.info(\"Batch uploaded intents and training phrases to new agent\")\n",
    "\n",
    "    # train the agent #1\n",
    "    print(\"Training Agent 1\")\n",
    "    train_agent_request = dialogflow.TrainAgentRequest(parent=test_project_path)\n",
    "    response = agent_client.train_agent(train_agent_request, timeout=240)\n",
    "    time.sleep(120) #added in case it goes too fast\n",
    "    logging.info(\"Trained the agent the 1st time\")\n",
    "    \n",
    "    # train the agent #2\n",
    "    print(\"Training Agent 2\")\n",
    "    train_agent_request = dialogflow.TrainAgentRequest(parent=test_project_path)\n",
    "    response = agent_client.train_agent(train_agent_request, timeout=240)\n",
    "    time.sleep(120) #added in case it goes too fast\n",
    "    logging.info(\"Trained the agent the 2nd time\")\n",
    "\n",
    "    \n",
    "    # create a new session with agent\n",
    "    session = session_client.session_path(test_project_id, random_with_N_digits(9))\n",
    "    logging.info(\"Created a new session\")\n",
    "    \n",
    "    #prepare Dialogflow parts for prediction by converting parts to text\n",
    "    prediction_list = pepare_df_text_for_prediction(X_test)\n",
    "    logging.info(\"Converted Dialogflow parts to text for prediction\")\n",
    "\n",
    "    #predict the intent name and confidence score\n",
    "    print(\"Making predictions\")\n",
    "    logging.info(\"Started making predictions\")\n",
    "    predicted_intent_name = []\n",
    "    predicted_confid_score = []\n",
    "    \n",
    "    query_params = dialogflow.QueryParameters(knowledge_base_names=[new_kb_path])\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    for i in tqdm(range(len(prediction_list))):\n",
    "        if count < api_interval_limit:\n",
    "            \n",
    "            rpc_error = True\n",
    "            while rpc_error==True:\n",
    "                try:\n",
    "                    predicted_intent, confidence_score = dialogflow_prediction(prediction_list[i], default_language_code, session, query_params)\n",
    "                    rpc_error = False\n",
    "                except:\n",
    "                    rpc_error = True\n",
    "            predicted_intent_name.append(predicted_intent)\n",
    "            predicted_confid_score.append(confidence_score)\n",
    "            count +=1   \n",
    "            \n",
    "        elif count ==api_interval_limit:\n",
    "            time.sleep(api_sleep_time)\n",
    "            \n",
    "            rpc_error = True\n",
    "            while rpc_error==True:\n",
    "                try:\n",
    "                    predicted_intent, confidence_score = dialogflow_prediction(prediction_list[i], default_language_code, session, query_params)\n",
    "                    rpc_error = False\n",
    "                except:\n",
    "                    rpc_error = True\n",
    "                \n",
    "            predicted_intent_name.append(predicted_intent)\n",
    "            predicted_confid_score.append(confidence_score)\n",
    "            count = 0\n",
    "    logging.info(\"Ended making predictions\")\n",
    "    \n",
    "    # create dataframe of actual vs predicted\n",
    "    data = list(zip(prediction_list, y_test, predicted_intent_name, predicted_confid_score))\n",
    "    columns = ['text','actual_intent','pred_intent','pred_conf']\n",
    "    df_f1 = pd.DataFrame(data, columns=columns)\n",
    "    df_f1['test_num'] = test_num\n",
    "    results_df.append(df_f1)\n",
    "    logging.info(\"Created dataframe of actual vs predicted\")\n",
    "    \n",
    "    #delete agent once done to create a new agent with different training phrases\n",
    "    print(\"Deleting Agent\")\n",
    "    response = agent_client.delete_agent(parent=test_project_path, timeout=120)\n",
    "    logging.info(\"Agent Deleted\")\n",
    "    \n",
    "    test_num += 1\n",
    "    logging.info(\"The {} k-fold loop completed\".format(test_num))\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19a491-4278-447d-b542-94b871de7ff6",
   "metadata": {},
   "source": [
    "## 5. Save the cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debeb9c7-258a-47f3-b674-f1b2db62c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the view the results of the a k-fold test\n",
    "#results_df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ee2a97-19b9-4b0e-b817-8402a2794436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to pickle to be loaded for analysis\n",
    "\n",
    "pd.to_pickle(results_df,save_file_path+save_file_name)\n",
    "logging.info(\"The file is saved\")\n",
    "logging.info(\"Processing the k-fold cross-validation is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78be35-6bd3-4ba5-b294-1beec2fb62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45fe0c-4969-4568-9550-c782bd6a2d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
